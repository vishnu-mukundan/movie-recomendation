#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np


# In[2]:


credits=pd.read_csv('C:\\Users\\aryam\Desktop\\movieml\\tmdb_5000_credits.csv')
movies=pd.read_csv('C:\\Users\\aryam\Desktop\\movieml\\tmdb_5000_movies.csv')


# In[3]:


credits.head(1)


# In[4]:


movies.head(1)


# In[5]:


credits.shape


# In[6]:


movies.shape


# The first dataset contains the following features:-
# 
# movie_id - A unique identifier for each movie.
# 
# cast - The name of lead and supporting actors.
# 
# crew - The name of Director, Editor, Composer, Writer etc.
# 
# The second dataset has the following features:-
# 
# budget - The budget in which the movie was made.
# 
# genre - The genre of the movie, Action, Comedy ,Thriller etc.
# 
# homepage - A link to the homepage of the movie.
# 
# id - This is infact the movie_id as in the first dataset.
# 
# keywords - The keywords or tags related to the movie.
# 
# original_language - The language in which the movie was made.
# 
# original_title - The title of the movie before translation or adaptation.
# 
# overview - A brief description of the movie.
# 
# popularity - A numeric quantity specifying the movie popularity.
# 
# production_companies - The production house of the movie.
# 
# production_countries - The country in which it was produced.
# 
# release_date - The date on which it was released.
# 
# revenue - The worldwide revenue generated by the movie.
# 
# runtime - The running time of the movie in minutes.
# 
# status - "Released" or "Rumored".
# 
# tagline - Movie's tagline.
# 
# title - Title of the movie.
# 
# vote_average - average ratings the movie recieved.
# 
# vote_count - the count of votes recieved.
# 
# 

# In[7]:


# merge this two dataset
df = movies.merge(credits, on='title')


# In[8]:


df.head(1)


# In[9]:


df['genres'][0]


# In[10]:


df['keywords'][0]


# In[11]:


df['cast'][0]


# In[12]:


df['crew'][0]


# In[13]:


import ast


# In[14]:


def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name']) 
    return L 


# In[15]:


df['genres'] = df['genres'].apply(convert)
df['keywords'] = df['keywords'].apply(convert)


# In[16]:


def convertc(text):
    L = []
    counter=0
    for i in ast.literal_eval(text):
        if counter != 3:
            L.append(i['name']) 
            counter+=1
        else:
            break
    return L 


# In[17]:


df["production_companies"]=df["production_companies"].apply(convertc)
df['cast']=df['cast'].apply(convertc)


# In[18]:


def director(text):
    L = []
    for i in ast.literal_eval(text):
        if i['job']=="Director":
            L.append(i['name'])
            break
    return L 


# In[19]:


df['crew']=df['crew'].apply(director)


# In[20]:


df.head()


# In[21]:


df['overview']


# In[22]:


df['overview']=df['overview'].str.split()


# In[23]:


df['overview']


# In[24]:


df.columns


# In[25]:


df.isna().sum()


# In[26]:


df2=df


# In[27]:


df=df[["budget", "popularity", "production_companies", "release_date", "revenue", "title", "movie_id", "overview", "genres", "keywords", "cast", "crew"]]
df.head()


# In[28]:


df.isna().sum()


# In[29]:


df1 = df.dropna()


# In[30]:


df1.isna().sum()


# # EDA

# In[31]:


import matplotlib.pyplot as plt
import seaborn as sns


# In[32]:


eda=df1[["budget", "popularity", "production_companies", "release_date", "revenue", "title", "genres", "cast", "crew"]]
eda.head()


# In[33]:


#applyin lambda function to convert into format
eda['crew'] = eda['crew'].apply(lambda x: " ".join(x))
eda['genres'] = eda['genres'].apply(lambda x: " ".join(x))
eda['cast'] = eda['cast'].apply(lambda x: " ".join(x))
eda['production_companies'] = eda['production_companies'].apply(lambda x: " ".join(x))
eda.head()


# In[34]:


eda["year"]=pd.DatetimeIndex(eda['release_date']).year
eda['month']=pd.DatetimeIndex(eda['release_date']).month


# Distribution of movies year wise

# In[35]:


unique_title= eda.drop_duplicates(['title'])
unique_title=unique_title["year"].value_counts()


# In[36]:


unique_title.head(20)


# In[37]:


y=unique_title
x=unique_title.index


# In[38]:


g=sns.lineplot(x,y)
g.set(xlabel ="year", ylabel = "no of movies")
plt.show()


# year wise hit movies or blockbuster movies

# In[39]:


top_revenue = eda.sort_values(by='revenue', ascending=False)
top_revenue.head(10)


# In[40]:


top_revenue2=top_revenue.drop_duplicates(subset='year', keep='first', inplace=False)


# In[41]:


top_revenue2.head(10)


# In[42]:


top_revenue2=top_revenue2.sort_values(by=['year'], ascending=False)[:10]
top_revenue2= top_revenue2[['year', 'title', 'revenue']].head(10)
sns.barplot(data=top_revenue, x=top_revenue2['revenue'], y=top_revenue2['title'], hue=top_revenue2["year"])
plt.show()


# Top 10 most frequent production companies

# In[43]:


production_value_counts = eda['production_companies'].str.split(',', expand=True).stack().value_counts()


# In[44]:


x=production_value_counts[1:10]
x


# In[45]:


y=production_value_counts.index[1:10]
y


# In[46]:


g5=plt.barh(y,x)
plt.xlabel=('no. of movies')
plt.ylabel=('production companies')


# Top 10 most frequent movie genres

# In[47]:


genres_value_counts = eda['genres'].str.split(',', expand=True).stack().value_counts()
genres_value_counts.head(10)


# In[48]:


y=genres_value_counts[:10]
x=genres_value_counts.index[:10]
plt.barh(x,y)
plt.show()


# Top 10 high budget movies

# In[49]:


top_budget = eda.sort_values(by='budget', ascending=False)


# In[50]:


sns.barplot(y=top_budget['title'][:10], x=top_budget['budget'][:10], data = top_budget)
plt.show()


# Top 10 high revenue earned movies

# In[51]:


top_revenue = eda.sort_values(by='revenue', ascending=False)


# In[52]:


sns.barplot(y=top_revenue['title'][:10], x=top_revenue['revenue'][:10], data = top_revenue)
plt.show()


# Top 10 most revenue earned movie's director

# In[53]:


sns.barplot(y=top_revenue['crew'][:10], x=top_revenue['revenue'][:10], data = top_revenue)
plt.show()


# Top 10 popularity movies

# In[54]:


top_popularity = eda.sort_values(by='popularity', ascending=False)


# In[55]:


sns.barplot(y=top_popularity['title'][:10], x=top_popularity['popularity'][:10], data = top_revenue)
plt.show()


# Top 10 director who made movies

# In[56]:


crew_value_counts = eda['crew'].value_counts()
x = crew_value_counts[1:10]
y = crew_value_counts.index[1:10]
plt.barh(y,x)
plt.show()


# Top 10 most revenue earned movie's director

# In[57]:


sns.barplot(data=top_revenue[:10], x='revenue', y='crew', hue='title')
plt.show()


# Top 10 revenue movies production companies

# In[58]:


revenue_comp=top_revenue[["production_companies", "title", "revenue"]]
sns.barplot(data=revenue_comp[:10], x='revenue', y= 'production_companies')
plt.show()


# Top avg revenue earned production company

# In[59]:


avg_prodc=eda.groupby("production_companies")["revenue"].mean()
avg_prodc=avg_prodc.nlargest(10)
sns.barplot(y=avg_prodc.index, x=avg_prodc)
plt.show()


# # Recommend movies to users Using Weighted average

# In[60]:


# Calculate all the components based on the  formula

v=df2['vote_count']
#print(v)
C=df2['vote_average'].mean()
#print(C)
R=df2['vote_average']
#print(R)


# In[61]:


#### The next step is to determine an appropriate value for m, the minimum votes required to be listed in the chart. 
#### We will use 90th percentile as our cutoff. In other words, for a movie to feature in the charts, 
#### it must have more votes than at least 90% of the movies in the list.


# In[62]:


m=df2['vote_count'].quantile(0.9)
m


# In[63]:


def weighted_avg_rating(x,m=m,C=C):
    v=x['vote_count']
    R=x['vote_average']
    
    return ((R*v) + (C*m))/(v + m)


# In[64]:


# Define a new feature 'weighted_avg' and calculate value of `avg_weighted_rating'
df2['weighted_avg']=df2.apply(weighted_avg_rating,axis=1)


# In[65]:


df_sorted_ranking=df2.sort_values('weighted_avg',ascending=False)


# In[66]:


#most recommended movies on the basis of Weighted avg


# In[67]:


sns.barplot(x=df_sorted_ranking['weighted_avg'].head(10),y=df_sorted_ranking['original_title'].head(10),data=df_sorted_ranking)
plt.xlim(4,10)
plt.title('Best scores by avg votes')
plt.show()


# # Popularity Based Recommendation System

# In[68]:


#we find movies that are very popular and they can just be obtained by 
# sorting the dataset by the popularity column.

popularity=df2.sort_values('popularity',ascending=False)


# In[69]:


popularity.reset_index(drop=True, inplace=True)


# In[70]:


popularity2=popularity[['movie_id','original_title','popularity','vote_average', 'vote_count']]


# In[71]:


popularity2


# In[72]:


x=popularity2.set_index('original_title')['popularity'].nlargest(10)
x=pd.DataFrame(x)
x


# In[73]:


x.plot(kind='bar')
plt.title('Most popularity movies')
plt.show()


# # CONTENT BASED RECOMMENDER SYSTEM

# In[74]:


content=df[['movie_id','title','overview','genres','keywords','cast','crew']]


# In[75]:


content.head()


# In[76]:


content.isna().sum()


# In[77]:


content.info()


# In[78]:


content['genres']


# In[79]:


content['genres']=content['genres'].apply(lambda x:[i.replace(" ","")for i in x])
content['keywords']=content['keywords'].apply(lambda x:[i.replace(" ","")for i in x])
content['cast']=content['cast'].apply(lambda x:[i.replace(" ","")for i in x])
content['crew']=content['crew'].apply(lambda x:[i.replace(" ","")for i in x])


# In[80]:


content['genres']


# In[81]:


content.head()


# In[82]:


content['tags'] = content['overview'] + content['genres'] + content['keywords'] + content['cast'] + content['crew']


# In[83]:


content=content.drop(columns=['overview','genres','keywords','cast','crew'],axis=1)


# In[84]:


content.head()


# In[85]:


content['tags'] = content['tags'].str.join(" ")


# In[86]:


content.head()


# In[87]:


content.info()


# In[88]:


content['tags']=content['tags'].str.lower()


# In[89]:


from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(stop_words='english')


# In[90]:


vectors=cv.fit_transform(content['tags'].values.astype('U')).toarray()
vectors


# In[91]:


cv.get_feature_names()


# In[92]:


from nltk.stem import PorterStemmer


# In[93]:


## Stemming
st = PorterStemmer()
content['tags'] = content['tags'].apply(lambda x: " ".join([st.stem(word) for word in str(x).split()]))


# In[94]:


content['tags'].head()


# In[95]:


from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(stop_words='english')


# In[96]:


vectors=cv.fit_transform(content['tags'].values.astype('U')).toarray()
vectors


# In[97]:


cv.get_feature_names()


# In[98]:


from sklearn.metrics.pairwise import cosine_similarity


# In[99]:


similarity=cosine_similarity(vectors)


# In[100]:


similarity


# In[101]:


# sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]


# In[102]:


def suggest(movie):
    movie_index = content[content['title'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]
    
    for i in movies_list:
        print(content.iloc[i[0]].title)


# In[103]:


suggest('Titanic')


# In[ ]:





# In[ ]:





# In[ ]:





# In[104]:


import pickle


# In[105]:


pickle.dump(content.to_dict(),open('movie_dict.pkl','wb'))


# In[106]:


pickle.dump(similarity,open('similarity.pkl','wb'))


# In[ ]:





# In[ ]:




